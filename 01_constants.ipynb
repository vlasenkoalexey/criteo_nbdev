{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from enum import Enum\n",
    "from google.cloud import bigquery\n",
    "\n",
    "PROJECT_ID = \"alekseyv-scalableai-dev\" #@param {type:\"string\"}\n",
    "LOCATION = 'us'\n",
    "SERVICE_ACCOUNT_KEY_FILE_NAME = 'service_account_key.json'\n",
    "\n",
    "GCS_BUCKET = 'gs://alekseyv-scalableai-dev-public-bucket/'\n",
    "GCS_FOLDER = GCS_BUCKET + 'criteo_kaggle/'\n",
    "PRIVATE_GCS_BUCKET = 'gs://alekseyv-scalableai-dev-private-bucket'\n",
    "\n",
    "URL = GCS_BUCKET + 'criteo_kaggle_decompressed/train.txt'\n",
    "DATASET_ID = 'criteo_kaggle_2'\n",
    "TABLE_ID = 'days'\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "#TODO: add tiny dataset\n",
    "DATASET_SIZE_TYPE = Enum('DATASET_SIZE_TYPE', 'full small tiny')\n",
    "DATASET_SIZE = DATASET_SIZE_TYPE.small\n",
    "\n",
    "DATASET_SOURCE_TYPE = Enum('DATASET_SOURCE_TYPE', 'bq gcs')\n",
    "DATASET_SOURCE = DATASET_SOURCE_TYPE.bq\n",
    "\n",
    "DATASET_TYPE = Enum('DATASET_TYPE', 'training validation')\n",
    "\n",
    "EMBEDDINGS_MODE_TYPE = Enum('EMBEDDINGS_MODE_TYPE',\n",
    "                            'none manual hashbucket vocabular')\n",
    "\n",
    "CSV_SCHEMA = [\n",
    "      bigquery.SchemaField(\"label\", \"INTEGER\", mode='REQUIRED'),\n",
    "      bigquery.SchemaField(\"int1\", \"INTEGER\"),\n",
    "      bigquery.SchemaField(\"int2\", \"INTEGER\"),\n",
    "      bigquery.SchemaField(\"int3\", \"INTEGER\"),\n",
    "      bigquery.SchemaField(\"int4\", \"INTEGER\"),\n",
    "      bigquery.SchemaField(\"int5\", \"INTEGER\"),\n",
    "      bigquery.SchemaField(\"int6\", \"INTEGER\"),\n",
    "      bigquery.SchemaField(\"int7\", \"INTEGER\"),\n",
    "      bigquery.SchemaField(\"int8\", \"INTEGER\"),\n",
    "      bigquery.SchemaField(\"int9\", \"INTEGER\"),\n",
    "      bigquery.SchemaField(\"int10\", \"INTEGER\"),\n",
    "      bigquery.SchemaField(\"int11\", \"INTEGER\"),\n",
    "      bigquery.SchemaField(\"int12\", \"INTEGER\"),\n",
    "      bigquery.SchemaField(\"int13\", \"INTEGER\"),\n",
    "      bigquery.SchemaField(\"cat1\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat2\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat3\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat4\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat5\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat6\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat7\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat8\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat9\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat10\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat11\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat12\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat13\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat14\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat15\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat16\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat17\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat18\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat19\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat20\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat21\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat22\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat23\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat24\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat25\", \"STRING\"),\n",
    "      bigquery.SchemaField(\"cat26\", \"STRING\")\n",
    "  ]\n",
    "\n",
    "FULL_TRAINING_DATASET_SIZE = 42840617\n",
    "FULL_VALIDATION_DATASET_SIZE = 3000000\n",
    "SMALL_TRAINING_DATASET_SIZE = 4500000\n",
    "SMALL_VALIDATION_DATASET_SIZE = 500000\n",
    "TINY_TRAINING_DATASET_SIZE = 500000\n",
    "TINY_VALIDATION_DATASET_SIZE = 500000\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
